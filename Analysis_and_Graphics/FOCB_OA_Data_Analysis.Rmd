---
title: "Analysis of OA Data From FOCB"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "7/15/2020"
output:
  github_document:
    toc: true
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

```{r load_libraries}
library(tidyverse)
library(readxl)
library(readr)

library(GGally)
library(zoo)
library(lubridate)  # here, for the make_datetime() function

library(CBEPgraphics)
load_cbep_fonts()
```

# Load Data
## Establish Folder Reference
```{r folder_refs}
sibfldnm <- 'Data'
parent   <- dirname(getwd())
sibling  <- file.path(parent,sibfldnm)

fn    <- 'CMS1 Data through 2019.xlsx'
fpath <- file.path(sibling,fn)

dir.create(file.path(getwd(), 'figures'), showWarnings = FALSE)
```

## Load The Data
We need to skip  the second row here, which is inconvenient largely because the
default "guess" of data contents for each column is based on the contents of
that first row of data.

A solution in an answer to this stack overflow questions
(https://stackoverflow.com/questions/51673418/how-to-skip-the-second-row-using-readxl)
suggests reading in the first row only to generate names, then skip the row of
names and the row of units, and read the "REAL" data.

Note that we round the timestamp on the data to the nearest hour.

### Primary Data
```{r load_data, warning = FALSE}
mynames <- read_excel(fpath, sheet = 'Sheet1', n_max = 1, col_names = FALSE)
mynames <- unname(unlist(mynames[1,]))  # flatten and simplify
mynames[2] <- 'datetime'               # 
mynames[4] <- 'depth'                   # Address non-standard names
mynames[8] <- 'pctsat'
mynames[18] <- 'omega_a'
mynames <- tolower(mynames)             # convert all to lower case

the_data <- read_excel(fpath, skip=2, col_names = FALSE)
names(the_data) <- mynames
rm(mynames)
```

```{r create_timestamp}
the_data <- the_data %>%
  select(-count, -time, -datetime)  %>%       # datetime and time contain the same data
  mutate(dt = make_datetime(year, month, day, hour, 0, tz = "America/New_York")) %>%
  rename(datetime = dt) %>%
  mutate(thedate  = as.Date(datetime),
         doy      = as.numeric(format(datetime, format = '%j')),
         tstamp   = paste0(year, '/', sprintf("%02d", month), '/',
                           sprintf("%02d", day), ' ', sprintf("%02d", hour)),
         Month = factor(month, labels = month.abb)) %>%
  arrange(datetime)              # Confirm that data are in chronological order
```

### CO2SYS Results
We ran CO2SYS in Python, principally to calculate estimated pH under the total 
pH scale.  Here we load it and use a left join by timestamp to add the data to 
the principal data set. 

```{r load_CO2SYS}
niecefldnm <- 'PyCO2SYS_Calc'
niece  <- file.path(sibling, niecefldnm)

fn    <- 'focbco2sys_out.csv'
fpath <- file.path(niece,fn)


ph_tot_data <- read_csv(fpath, 
    col_types   = cols(month = col_integer(), 
        year    = col_integer(), 
        day     = col_integer(), 
        hour    = col_integer(), 
        temp    = col_number(), 
        sal     = col_number(), 
        pco2    = col_number(), 
        ph      = col_number(), 
        omega_a = col_number(), 
        omega_c = col_number(), 
        ta      = col_number(), 
        dic     = col_number(),
        ph_tot  = col_number())) %>%
  mutate(tstamp = paste0(year, '/', sprintf("%02d", month), '/',
                         sprintf("%02d", day), ' ', sprintf("%02d", hour))) %>%
  select(ph_tot, tstamp)
```

### Merge pH (Total Scale) data into primary data
Note this assumes there are no duplicate timestamps....

```{r merge_in pH data}

the_data <- the_data %>%
  left_join(ph_tot_data, by='tstamp') %>%
  select(-tstamp)
rm(ph_tot_data)
```

## Takahashi et al. 2002 Relationships
Here we follow a formula for calculating a "Temperature Corrected" pCO~2~, which
is derived from methods in Takahashi et al. 2002. The "temperature corrected"
version adjusts for the thermodynamic effect of temperature on pCO~2~.

> Takahashi, Taro & Sutherland, Stewart & Sweeney, Colm & Poisson, Alain &
  Metzl, Nicolas & Tilbrook, Bronte & Bates, Nicholas & Wanninkhof, Rik & Feely,
  Richard & Chris, Sabine & Olafsson, Jon & Nojiri, Yukihiro. (2002). Global
  sea-air CO2 flux based on climatological surface ocean pCO2, and seasonal
  biological and temperature effects. Deep Sea Research Part II: Topical Studies
 in Oceanography. 49. 1601-1622. 10.1016/S0967-0645(02)00003-6.

Takahashi et al. 2002 Used direct calculation of "temperature corrected" pCO~2~
as a surrogate for changes in CO~2~ concentration, and conversely, estimates of
"expected" thermal pCO~2~, as estimates of the magnitude of the fluctuations in
pCO~2~ one would expect to see due to temperature alone, if there were no
changes in [CO~2~].

The Takahashi et al. 2002 equations are as follows:

#### "Expected pCO~2~" at Observed Temperature
$$(pCO_{2} \textrm{ at }T_{\textrm{obs}}) = (pCO_{2})_{\textrm{obs}} 
\times exp(0.0423(T_{\textrm{obs}}- T_{\textrm{mean}})$$

#### "Temperature Corrected" pCO~2~
$$(pCO_{2} \textrm{ at }T_{\textrm{mean}}) = (pCO_{2})_{\textrm{obs}} \times exp(0.0423(T_{\textrm{mean}}- T_{\textrm{obs}})$$

### Calculations
Here we calculate the "temperature corrected" time series as calculated in
Takahashi et al. "Temperature Corrected" pCO~2~ value ("co2_corr") provides a
trace of changes in pCO~2~ that "would have happened" in the absence of
temperature changes.  These reflect changes in the concentration of CO~2~, which
reflect a combination of biology and diffusion of CO~2~ between ocean and
atmosphere and advection past the sensor by tides and currents. Here we adjust
pCO~2~ to a "standard temperature" of 12 degrees C.  This is slightly warmer
than  the observed annual average temperature. We use 12 degrees C for
consistency with analysis of the CBEP / UNH data.

```{r calc_pco2_corr}
t_ref = 12
the_data <- the_data %>%
  mutate(pco2_corr =  pco2*exp(0.0423*(t_ref-temperature))) %>%
  select(c(16, 17, 11, 10, 9, 19, 12,  18, 1:5, 7,  6, 20, 8, 21, 13:15))  # reorder for convenience
rm(t_ref)
```

## Create Long Form Data
```{r long_data}
long_data <- the_data %>%
  relocate(day, .after = hour) %>%
  relocate(hour, .after = doy) %>%
  pivot_longer(cols= depth:omega_a, 
               names_to='Parameter', values_to = 'Value') %>%
  mutate(Parameter = factor(Parameter,
                            levels = c('depth',
                                       'temperature',
                                       'salinity',
                                       'do',
                                       'pctsat',
                                       'chl',
                                       'ph',
                                       'ph_tot',
                                       'pco2',
                                       'pco2_corr',
                                       'ta',
                                       'dic',
                                       'omega-a')))
```

## Create Daily Data Summaries
```{r daily_data}
daily_data <- the_data %>%
  select(-hour, -year, -month, -day, -doy) %>%         # Will recalculate these 
  group_by(thedate) %>%
  summarise_at(c("temperature", "salinity", "do", 
                 "pctsat", "chl", "ph", "ph_tot",
                 "pco2", "pco2_corr", "ta", "dic", 'omega_a'),
               c(a    = function(x) mean(x, na.rm=TRUE),
                 m    = function(x) median(x, na.rm=TRUE),
                 r    = function(x) {suppressWarnings(max(x, na.rm=TRUE) -
                                                        min(x, na.rm=TRUE))},
                iqr  = function(x) IQR(x, na.rm=TRUE),
                p80r = function(x) {as.numeric(quantile(x, 0.90, na.rm=TRUE) -
                       quantile(x, 0.10, na.rm=TRUE))})) %>%
  mutate(year = as.numeric(format(thedate, format = '%Y')),
         month  = as.numeric(format(thedate, format = '%m')),
         dd   = as.numeric(format(thedate, format = '%d')),
         doy  = as.numeric(format(thedate, format = '%j')),
         Month = factor(month, levels=1:12, labels = month.abb)
         )
```

## Calculate Diurnal Deviations
We calculate hourly deviation from daily averages for the principal OA measures. 
This allows us to look at diurnal patterns.

```{r hourly_deviations}
diurnal_data <- the_data %>%
  group_by(thedate) %>%
  
  # Calculate sample sizes for each day.
  mutate(pco2_n      = sum(! is.na(pco2)),
         pco2_corr_n = sum(! is.na(pco2_corr)),
         ph_n        = sum(! is.na(ph)),
         ph_tot_n    = sum(! is.na(ph_tot)),
         omega_n     = sum(! is.na(omega_a))) %>%
  
  # Calculate centered but not scaled values, day by day.
  mutate(pco2_res      = scale(pco2, scale = FALSE),
         pco2_corr_res = scale(pco2_corr, scale = FALSE),
         ph_res        = scale(ph, scale = FALSE),
         ph_tot_res    = scale(ph_tot, scale = FALSE),
         omega_res     = scale(omega_a, scale=FALSE)) %>%
  ungroup() %>%
  
  # Replace data from any days with less than 20 hours of data with NA
  mutate(pco2_res      = ifelse(pco2_n>=20, pco2_res, NA),
         pco2_corr_res = ifelse(pco2_corr_n>=20, pco2_corr_res, NA),
         ph_res        = ifelse(ph_n>=20, ph_res, NA),
         ph_tot_res    = ifelse(ph_tot_n>=20, ph_res, NA),
         omega_res     = ifelse(omega_n>=20, ph_res, NA)) %>%
  
  # Delete the daily sample size variables
  select(-contains("_n")) %>%
  mutate(Month = factor(month, levels = 1:12, labels=month.abb))
```

# Exploratory Graphics
```{r pairs_plot_1, warning=FALSE}
the_data %>% 
  ggpairs(c(10:12, 13:14), progress=FALSE)
```

What jumps out most strongly is the negative association between temperature and
DO. Most of the negative association between DO and temperature vanishes when
looking at percent saturation. Temperature shows a strong bimodal distribution,
presumably because of winter and summer temperature regimes. DO shows weak
bimodal structure, but percent saturation does not.

```{r pairs_plot_2, warning=FALSE}
the_data %>% ggpairs(c(10:12, 15:18), progress=FALSE)
```

Mutual temperature dependence of DO and pCO~2~ means those two variables are
negatively correlated.  WEAK negative association remains even after temperature
correction, so this is not just a thermodynamic relationship.  (Don't trust
statistical significance as observations have very high autocorrelation.)

Negative pH PCO2 relationships are fairly robust here. They are stronger before 
temperature correction.

There are a few wonky observations.  They look like high pCO2, moderate low 
salinity in moderately cool temperatures.  I bet they are all a big storm 
event...

```{r pairs_plot_3, warning=FALSE}
the_data %>% ggpairs(c(10:12, 17:21), progress=FALSE)
```
Calculates total alkalinity and dissolved inorganic carbon are nearly measuring
the same thing -- no surprise in sea water.

Don't believe the measures of statistical significance here, as the implied
models do not account for very high autocorrelations.  Checking these
correlations will involve developing GAMM models.

# Summary Statistics
## Entire Data Set
This is legacy code. It would be easier today to develop this in the tidyverse.
```{r summary_stats}
the.mins     <- sapply(the_data[9:21], min, na.rm=TRUE)
the.medians  <- sapply(the_data[9:21], median, na.rm=TRUE)
the.means    <- sapply(the_data[9:21], mean, na.rm=TRUE)
the.maxes    <- sapply(the_data[9:21], max, na.rm=TRUE)
the.SDs  <-   sapply(the_data[9:21], sd, na.rm=TRUE)
the.samplesizes <-  sapply(the_data[9:21], function(x) sum(! is.na(x)) )
result   <-  cbind(the.mins, the.medians, the.means, the.maxes, 
                   the.SDs, the.samplesizes)
colnames(result) <- c('Minimum', 'Median', 'Mean', 'Maximum', 
                      'Std. Deviation', 'Observations')
rownames(result) <- c('Depth',
                      'Temperature',
                      'Salinity',
                      'DO (mg/l)',
                      'Percent Saturation',
                      'Chlorophyll-a',
                      'pH (NMS)',
                      'pH (Total, calculated)',
                      'pCO2',
                      'pCO2_corr',
                      'Total Alkalinity',
                      'Dissolved Inorganic Carbon',
                      'Omega Aragonite'
                      )
knitr::kable(result, digits = c(1,1,2,1,3,0))
```

```{r cleanup, echo=FALSE}
rm(the.mins, the.means, the.medians, the.maxes, 
   the.SDs, the.samplesizes, result)
```

## Omega Aragonite Observations and Percentage Below Levels of Concern
```{r levels_of_concern_1}
below1.5 <- sum(the_data$omega_a<1.5, na.rm=TRUE)
below1.0 <- sum(the_data$omega_a<1.0, na.rm=TRUE)
TotObs   <- sum(! is.na(the_data$omega_a))
pctbelow1.5 <- below1.5/TotObs
pctbelow1.0 <- below1.0/TotObs

res <- unlist( list(`Count Below 1.0` = below1.0,
                    `Count Below 1.5` = below1.5,
      `Observations` = TotObs,
      `Percent Below 1.0` = pctbelow1.0,
      `Percent Below 1.5` =pctbelow1.5))
rm(below1.0, below1.5, TotObs, pctbelow1.0, pctbelow1.5)
knitr::kable(t(res), digits = c(0,0,0,3,3))
```

## Daily Omega Aragonite (medians) Observations and and Percentage Below Levels of Concern
```{r daily_levels_of_concern}
below1.5 <- sum(daily_data$omega_a_m<1.5, na.rm=TRUE)
below1.0 <- sum(daily_data$omega_a_m<1.0, na.rm=TRUE)
TotObs   <- sum(! is.na(daily_data$omega_a_m))
pctbelow1.5 <- below1.5/TotObs
pctbelow1.0 <- below1.0/TotObs

res <- unlist(list(`Count Below 1.0` = below1.0, `Count Below 1.5` = below1.5,
      `Observations` = TotObs,
      `Percent Below 1.0` = pctbelow1.0,
      `Percent Below 1.5` =pctbelow1.5))
rm(below1.0, below1.5, TotObs, pctbelow1.0, pctbelow1.5)
knitr::kable(t(res), digits = c(0,0,0,3,3))
```

## Monthly Summary Statistics
This is means **across** years.  This is NOT the same as an estimated monthly
average, adjusted for year to year variation, imbalances in time of day data was
collected, etc.  For that, we would need to estimate marginal means from a GAMM.
We do not pursue that idea in this notebook.

```{r monthly_stats}
monthly_tbl <- the_data %>%
  select(datetime, year, Month, temperature, salinity, do, pctsat, 
         chl, ph, ph_tot, pco2, pco2_corr, omega_a) %>%

  pivot_longer(temperature:omega_a, names_to = 'parameter',
               values_to = 'value') %>%
  group_by(Month, parameter) %>%
  summarise(
    avg    = round(mean(value, na.rm = TRUE), 2),
    median = round(median(value, na.rm = TRUE), 2),
    sd     = round(sd(value, na.rm = TRUE), 3),
    count  = sum(!is.na(value))
  ) %>%
  pivot_longer(cols = c('avg', 'median', 'sd', 'count'),
               names_to = 'label') %>%
  pivot_wider(id_cols = c(parameter, label), names_from=Month) 
knitr::kable(monthly_tbl)
```

# Base Graphics
## Constants for Axis Labels
```{r axis_setup}
monthlengths <-  c(31,28,31, 30,31,30,31,31,30,31,30,31)
cutpoints    <- c(0, cumsum(monthlengths)[1:12])
monthlabs    <- c(month.abb,'')
```

## Seasonal Profiles
These graphs combine data from multiple years to generate a picture of seasonal
conditions across multiple years.  Since data coverage is inconsistent year to
year, data for some times of year are derived from just one or two years, which
could bias the results.

### Raw pCO2
```{r pc02_Raw_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, pco2)) + 
  geom_point(aes(color = factor(year)), alpha = 0.1) +
  
  geom_hline(aes(yintercept = 400), lty = 'solid', color = 'gray') +
  annotate('text', x=0, y=430, label= expression(pCO[2*(cor)]~'='~ 400),
           hjust = 0, size=3) +
  
  xlab('') +
  ylab(expression (pCO[2]~(mu*Atm))) +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
ggsave('figures/pco2RawSeasonal_focb.pdf', device=cairo_pdf,
       width = 7, height = 5)
```

### Temperature Corrected pCO2
It's not technically OK to show a reference line on a figure with 
temperature-corrected pCO2.  The equilibrium between [co~2~] and fugacity 
is temperature dependent.

```{r pc02_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, pco2_corr)) + 
  geom_point(aes(color = factor(year)), alpha = 0.1) +
  
  # geom_hline(aes(yintercept = 400), lty = 'dotted', color = 'gray') +
  # annotate('text', x=365, y=370, label= expression(pCO[2*(cor)]~'='~ 400), 
  # hjust=1, size=3) +
  
  xlab('') +
  ylab(expression (pCO[2*(cor)]~(mu*Atm))) +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
ggsave('figures/pco2Seasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)
```

This shows much less obvious seasonality than the CBEP / UNH site.

### Both Raw and Corrected pco~2~ on One Graph.
```{r pco2_comparison, fig.height = 2, fig.width = 3}
plt  <- long_data %>% filter(Parameter %in% c('pco2', 'pco2_corr')) %>%
  
  mutate(Parameter = factor(Parameter, levels = c('pco2', 'pco2_corr'),
                            labels = c('Observed',
                                       'Temp. Corrected'))) %>% 
  
  ggplot(aes(x=doy, y=Value, alpha=Parameter)) +
  geom_line(aes(color = Parameter)) +
 
  scale_alpha_discrete(range = c(0.75, 0.5), name = '') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) + 
  scale_color_manual(values=cbep_colors2(), name='') +

  xlab('') +
  ylab(expression (pCO[2]~(mu*Atm))) +

  #guides(colour = guide_legend(override.aes = list(alpha = c(0.25, 1)))) +
  
  theme_cbep(base_size = 10) +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5)) +
  theme(legend.position= c(.3, .8))
plt
ggsave('figures/pco2compare_focb.pdf', device=cairo_pdf, width = 3, height = 2)
```

### pH (Total Scale)
```{r ph_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, ph_tot)) + 
  geom_point(aes(color = factor(year)),alpha = 0.05) +
  xlab('') +
  ylab('pH') +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +

  scale_y_continuous(limits = c(7.5, 8.5), 
                     breaks = c(7.5, 7.75, 8.0, 8.25, 8.5)) +
  
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
ggsave('figures/phSeasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)
```

### Aragonite Saturation State
```{r omega_by_doy, fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, omega_a)) + 
  geom_point(aes(color = factor(year)), alpha = 0.1) +
  geom_hline(aes(yintercept = 1), lty = 'solid', color = 'gray') +
  geom_text(aes(x=0, y=1.1, label= 'Omega = 1.0', hjust = 0), size=3) +
  
  xlab('') +
  ylab(expression(Omega[a])) +
  
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
ggsave('figures/omegaSeasonal_focb.pdf', device=cairo_pdf, 
       width = 7, height = 5)
```

# Daily Patterns
```{r reorganize data}
long_diurnal_data <- diurnal_data %>% select(-c(9:16)) %>%  # Drop all raw observations; retain diurnal residuals
                                               
  pivot_longer(contains("_res"), names_to='metric') %>%
  mutate(metric= sub("_res", "", metric))       #simplify names
```

## Diurnal Trendlines
Here we display trendlines derived from GAM models by month.  As noted above, 
these models are likely to slightly overfit the trends.

Notice that the selection of the dimension of the periodic basis of the smooths
in the GAM (signaled in k=6) is essentially selected here by eye to create a
visual balance between simplicity and complexity.  The default here probably
over-fits, as described above.  We explore the implied GAM (and related GAMM)
further in the another R Notebook.

```{r combined_plot, fig.width = 8, fig.height = 5}
labs <- c(expression(paste(pCO[2*(cor)], ' (', mu, 'Atm)')), 'pH')
names(labs) <- unique(long_diurnal_data$metric)[c(2,4)]

tmp <- long_diurnal_data %>%
  filter( metric %in% c('pco2_corr', 'ph_tot')) %>%
  mutate(metric = factor(metric, levels = names(labs), labels = labs))

plt <-
  ggplot(tmp, aes(hour,value, color = Month)) +
  geom_smooth(aes(color = Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE) +

  theme_cbep() +
  theme(panel.spacing = unit(2, "lines")) +
  
  xlab('Hour of the Day') +
  ylab('Difference from Daily Average') +
  facet_wrap(~metric, nrow=1, scales='free_y',
                   labeller = label_parsed ) +
  scale_color_discrete(name = "Month") + 
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
plt
ggsave('figures/dailyco2andphbymonth_focb.pdf', device = cairo_pdf, 
       width = 8, height = 5)
```

## Corrected pCO2 Graph
```{r pco2_figure, fig.width = 4, fig.height = 4, warning=FALSE}
plt <- diurnal_data %>%
  ggplot(aes(hour,pco2_corr_res)) +
  geom_smooth(aes(color=Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE, lwd=0.75) +
  theme_cbep(base_size = 12) +
  xlab('Hour of Day') +
  ylab(expression (atop(pCO[2*(cor)]~(mu*Atm), Difference~From~Daily~Average))) +
  scale_color_discrete(name = "Month") + 
  theme(legend.key.width = unit(0.25,"in"),
        legend.text      = element_text(size = 10)
        ) +
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
plt
ggsave('figures/dailyCO2bymonth_focb.pdf', device=cairo_pdf, 
       width = 4, height = 4)
```

## pH Graph
```{r phfigure, fig.width = 4, fig.height = 4, warning=FALSE}
plt <- diurnal_data %>%
  ggplot(aes(hour,ph_res)) +
  geom_smooth(aes(color=Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE) +
  theme_cbep(base_size = 12) +
  theme(legend.key.width = unit(0.25,"in"),
        legend.text      = element_text(size = 10)
        ) +
  xlab('Hour of Day') +
  ylab(expression (atop(pH, Difference~From~Daily~Average))) +
  scale_color_discrete(name = "Month") + 
  scale_linetype_discrete(name = "Month") + 
  theme(legend.key.width=unit(0.25,"in")) +
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
plt
ggsave('figures/dailyphbymonth_focb.pdf', device=cairo_pdf, 
       width = 4, height = 4)
```
